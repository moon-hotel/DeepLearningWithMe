
<div align=center>
<img width="300" src="https://moonhotel.oss-cn-shanghai.aliyuncs.com/images/230629150346.jpg"/> 
</div>

# 《跟我一起学深度学习》

- 作 者: @空字符
- 公众号: @月来客栈
- 知 乎: @月来客栈 https://www.zhihu.com/people/the_lastest

# 目录

## 第 1 章 深度学习简介
## 第 2 章 环境配置
## 第 3 章 深度学习基础
- [3.1 线性回归](https://mp.weixin.qq.com/s/DC5KhOElFvzC41QuheHfqQ)
- [3.2 线性回归简洁实现](https://mp.weixin.qq.com/s/DC5KhOElFvzC41QuheHfqQ)
- [3.3 梯度下降与反向传播](https://mp.weixin.qq.com/s/LvBKle1HaYkkDAlPw7xIlA)
- [3.4 从零实现回归模型](https://mp.weixin.qq.com/s/KNq8yqZF_Bdc0cynrF5oEg)
- [3.5 从逻辑回归到Softmax回归](https://mp.weixin.qq.com/s/RgPKdixw8cL35ty6Fp6v_Q)
- [3.6 Softmax回归简洁实现](https://mp.weixin.qq.com/s/kdJqBsddT9DiXQ3CPtzl2g)
- [3.7 从零实现分类模型](https://mp.weixin.qq.com/s/Kc7t1rxUzSiZ3sbATGwBfg)
- [3.8 回归模型评估指标](https://mp.weixin.qq.com/s/a0Z2x0tR-Ov1z7OdKXajmQ)
- [3.9 分类模型评估指标](https://mp.weixin.qq.com/s/ia9hP8q3E1MbtpjSF1oTpw)
- [3.10 过拟合与正则化](https://mp.weixin.qq.com/s/ybtNmPc4Y0BMgtkhAL-XqA)
- [3.11 超参数与交叉验证](https://mp.weixin.qq.com/s/ygvTqiTx4__V41cnwnc2Uw)
- [3.12 激活函数](https://mp.weixin.qq.com/s/-FfUhIwSIW0A2E3www6YXQ)
## 第 4 章 卷积神经网络
- [4.1 卷积的概念](https://mp.weixin.qq.com/s/BWzs6hzS_5Cu38MrEZmo4Q)
- [4.2 卷积的计算过程](https://mp.weixin.qq.com/s/RXIZD9xiNvVsvJqlUYrmhA)
- [4.3 填充和池化](https://mp.weixin.qq.com/s/Li6GtIxCJn6gXktcTrs6OA)
- [4.4 LeNet5模型](https://mp.weixin.qq.com/s/Li6GtIxCJn6gXktcTrs6OA)
- [4.5 AlexNet模型](https://mp.weixin.qq.com/s/5AYMTe_QttplxwFscilolA)
- [4.6 VGG模型](https://mp.weixin.qq.com/s/zTfYYG5uhttq5doMHVfgSQ)
- [4.7 NIN模型](https://mp.weixin.qq.com/s/Js-Sv3N7nWJbr4O5JTz8fA)
- [4.8 GoogLeNet模型](https://mp.weixin.qq.com/s/KCg2GSSIiQltw9B_Zn7r8A)
- 4.9 ResNet模型
- 4.10 DenseNet模型
## 第 5 章 模型训练与复用
- 5.1 参数及日志管理
- 5.2 模型训练可视化
- 5.3 模型保存与复用
- 5.4 模型的迁移学习
- 5.5 开源模型复用
- 5.6 多GPU训练
- 5.7 数据预处理缓存
## 第 6 章 模型优化与泛化
- 6.1 学习率动态调整
- 6.2 梯度裁剪
- 6.3 标签平滑
- 6.4 批归一化
- 6.5 层归一化
- 6.6 组归一化
- 6.7 动量法
- 6.8 Adam算法
- 6.9 AdaDelta算法
- 6.10 AdaGrad算法
- 6.11 RMSprop算法
## 第 7 章 循环神经网络
## 第 8 章 时序任务与模型融合
## 第 9 章 自然语言处理
## 第 10章 现代神经网络
