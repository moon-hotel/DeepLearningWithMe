# 3.10 过拟合与正则化

经过前面几节内容的介绍， 我们对于深度学习的理念以及最基本的回归和分类模型已经有了清晰的认识。在接下来的这节内容中，笔者将逐步开始介绍深度学习中关于模型优化的一些基本内容，包括模型的过拟合、正则化和丢弃法等。

## 3.10.1 模型拟合

在第3.3节内容中，笔者首次引入了梯度下降这一优化算法，以此来最小化线性回归中的目标函数，并且在经过多次迭代后便可以得到模型中对应的参数。此时可以发现，模型的参数是一步一步根据梯度下降算法更新而来，直至目标函数收敛，也就是说这是一个循序渐进的过程，因此，这一过程也被称作拟合（Fitting）模型参数的过程，当这个过程执行结束后就会产生多种拟合后的状态，例如过拟合（Overfitting）和欠拟合（Underfitting）等。

在第3.8节内容中，笔者介绍了几种评估回归模型常用的指标，但现在有一个问题： 当MAE或者RMSE越小时就代表模型越好吗？还是说在某种条件下其越小就越好呢？细心的读者可能一眼便明了，肯定是有条件下的越小所对应的模型才越好。那这其中到底是怎么回事呢？

假设现在有一批样本点，它本是由函数$sin(x)$生成（现实中并不知道），但由于其他因素的缘故，使我们得到的样本点并没有准确地落在曲线$sin(x)$上，而是分布在其附近，如图3-38所示。

<div align=center>
<img width="380" src="../img/23020633449.jpg"/>
</div>

<center>
  图 3-38 正弦样本点图形
</center>

如图3-38所示，黑色圆点为训练集，黑色曲线为样本真实的分布曲线。现在需要根据训练集来建立并训练模型，然后得到相应的预测函数。现在我们分别用3个不同的模型A、B和C（复杂度依次增加，例如更多的网络层数和神经元个数等）来分别根据这12个样本点进行建模，那么最终便可以得到如图3-39所示的结果。

<div align=center>
<img width="380" src="../img/23020643127.jpg"/>
</div>

<center>
  图3-39正弦样本点拟合图形
</center>

从图3-39中可以看出，随着模型复杂度的增加，$R^2$指标的值也越来越大（$R^2\in(-\infty,1]$），并且在模型C中$R^2$还达到了1.0，但是最后就应该选择模型C吗？

不知到又过了多久，突然一名客户要买你的这个模型进行商业使用，同时客户为了评估这个模型的效果自己又带来了一批新的含有标签的数据（虽然模型C已经用$R^2$测试过，但客户并不会完全相信，万一你对这个模型作弊呢）。于是你拿着客户的新数据（也是由$sin(x)$所生成），然后分别用上面的3个模型进行预测，并得到了如图3-40所示的可视化结果。

<div align=center>
<img width="380" src="../img/23020658968.jpg"/>
</div>

<center>
  图 3-40 正弦样本点过拟合图形
</center>


如图3-40所示，各个曲线表示根据新样本预测值绘制得到的结果。此时令你感到奇怪的是，为什么模型B的结果居然会好于模型C的结果，问题出在哪里？其原因在于，当第1次通过这12个样本点进行建模时，为了尽可能地使“模型好（表现形式为$R^2$尽可能大）”而使用了非常复杂的模型，尽管最后每个训练样本点都“准确无误”地落在了预测曲线上，但是这却导致最后模型在新数据上的预测结果严重地偏离了其真实值。

## 3.10.2 过拟合与欠拟合概念

在机器学习领域中，通常将建模时所使用的数据叫作训练集（Training Dataset），例如图3-38中的12个样本点。将测试时所使用的数据集叫作测试集（Testing Dataset）。同时把模型在训练集上产生的误差叫作训练误差（Training Error），把模型在测试集上产生的误差叫作泛化误差（Generalization Error），最后也将整个拟合模型的过程称作训练（Training）[1]。

进一步讲，将3.10.1节中模型C所产生的现象叫作过拟合（Overfitting），即模型在训练集上的误差很小，但在测试集上的误差却很大，也就是泛化能力弱； 相反，将其对立面模型A所产生的现象叫作欠拟合（Underfitting），即模型训练集和测试集上的误差都很大； 同时，将模型B对应的现象叫作恰拟合（Goodfitting），即模型在训练集和测试集上都有着不错的效果。

同时，需要说明的是，在3.10.1节中笔者仅仅以回归任务为例来向读者直观地介绍了什么是过拟合与欠拟合，但并不代表这种现象只出现在回归模型中，事实上所有的深度学习模型都会存在着这样的问题，因此一般来讲，所谓过拟合现象指的是模型在训练集上表现很好，而在测试集上表现却糟糕，欠拟合现象是指模型在两者上的表现都十分糟糕，而过拟合现象是指模型在训练集上表现良好（尽管可能不如过拟合时好），但同时在测试集上也有着不错的表现。

## 3.10.3 解决欠拟合与过拟合

**1\. 如何解决欠拟合问题**

经过上面的描述我们已经对欠拟合有了一个直观的认识，所谓欠拟合就是训练出来的模型根本不能较好地拟合现有的训练数据。在深度学习中，要解决欠拟合问题相对来讲较为简单，主要分为以下3种方法： 

(1) 重新设计更为复杂的模型，例如增加网络的深度、神经元的个数或者采用更为复杂的网络架构（如Transformer）；

(2) 减小正则化系数，当模型出现欠拟合现象时，可以通过减小正则化中的惩罚系数来减缓欠拟合现象，这一点将在第3.10.4节中进行介绍。

**2\. 如何解决过拟合问题**

对于如何有效地缓解模型的过拟合现象，常见的做法主要分为以下4种方法： 

(1) 收集更多数据，这是一个最为有效但实际操作起来又是最为困难的一种方法。训练数据越多，在训练过程中也就越能够纠正噪声数据对模型所造成的影响，使模型不易过拟合，但是对于新数据的收集往往有较大的困难。

(2) 降低模型复杂度，当训练数据过少时，使用较为复杂的模型极易产生过拟合现象，例如3.10.1节中的示例，因此可以通过适当减少模型的复杂度来达到缓解模型过拟合的现象。

(3) 正则化方法，在出现过拟合现象的模型中加入正则化约束项，以此来降低模型过拟合的程度，这部分内容将在3.10.4节中进行介绍。

(4) 集成方法，将多个模型集成在一起，以此来达到缓解模型过拟合的目的。

**3\. 如何避免过拟合**

为了避免训练出来的模型产生过拟合现象，在模型训练之前一般会将获得的数据集划分成两部分，即训练集与测试集，且两者一般为7∶3的比例。其中训练集用来训练模型（降低模型在训练集上的误差），然后用测试集来测试模型在未知数据上的泛化误差，观察是否产生了过拟合现象 [2]。

但是由于一个完整的模型训练过程通常会先用训练集训练模型，再用测试集测试模型，而绝大多数情况下不可能第1次就选择了合适的模型，所以又会重新设计模型（如调整网络层数、正则化系数等）进行训练，然后用测试集进行测试，因此在不知不觉中，测试集也被当成了训练集在使用，所以这里还有另外一种数据的划分方式，即训练集、验证集（Validation Data）和测试集，且一般为7∶2∶1的比例，此时的测试集一般通过训练集和验证集选定模型后做最后测试所用。

实际训练中应该选择哪种划分方式呢？这一般取决于训练者对模型的要求程度。如果要求严苛就划分为3份，如果不那么严格，则可以划分为2份，也就是说这两者并没硬性的标准。

## 3.10.4 泛化误差的来源

根据第3.10.3节内容可以知道，模型产生过拟合的现象表现为在训练集上误差较小，而在测试集上误差较大，并且笔者还讲到，之所以会产生过拟合现象是由于训练数据中可能存在一定的噪声，而我们在训练模型时为了尽可能地做到拟合每个样本点（包括噪声），往往就会使用复杂的模型。最终使训练出来的模型在很大程度上受到了噪声数据的影响，例如真实的样本数据可能更符合一条直线，但是由于个别噪声的影响使训练出来的是一条曲线，从而使模型在测试集上表现糟糕，因此，可以将这一过程看作由糟糕的训练集导致了糟糕的泛化误差。但是，如果仅仅从过拟合的表现形式来看，糟糕的测试集（噪声多）也可能导致糟糕的泛化误差。

在接下来的内容中，笔者将分别从这两个角度来介绍正则化（Regularization）方法中最常用的$\mathcal{l} _2$正则化是如何来解决这一问题的。

这里以线性回归为例，我们首先来看一下在线性回归的目标函数后面再加上一个$\mathcal{l}_2$正则化项的形式。
$$
J=\sum\limits_{i=1}^{m}{{{\left( {{y}^{(i)}}-(\sum\limits_{j=1}^{n}{{{w}_{j}}x_{j}^{(i)}}+b) \right)}^{2}}}+\frac{\lambda }{2n}\sum\limits_{j=1}^{n}{{{({{w}_{j}})}^{2}}};\;\;(\lambda >0)\tag{4-6,3-98}
$$
在式(3-98)中的第2项便是新加入的$\mathcal{l}_2$正则化项（Regularization Term），那它有什么作用呢？根据第3.1.3节中的内容可知，当真实值与预测值之间的误差越小（表现为损失值趋于0）时，也就代表着模型的预测效果越好，并且可以通过最小化目标函数来达到这一目的。由式(3-98)可知，为了最小化目标函数$J$，第2项的结果也必将逐渐地趋于0。这使最终优化求解得到的$w_j$均会趋于0附近，进而得到一个平滑的预测模型。这样做的好处是什么呢？
