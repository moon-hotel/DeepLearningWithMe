"""
文件名: Code/Chapter07/C06_BiLSTM/main.py
创建时间: 2023/5/15 7:25 下午
作 者: @空字符
公众号: @月来客栈
知 乎: @月来客栈 https://www.zhihu.com/people/the_lastest
"""

import torch
import torch.nn as nn

torch.manual_seed(5)


def test_LSTM():
    batch_size = 3
    time_step = 5
    input_size = 6
    hidden_size = 4
    x = torch.rand([batch_size, time_step, input_size])  # [batch_size, time_step, input_size]
    lstm = nn.LSTM(input_size, hidden_size, num_layers=1,
                   batch_first=True, bidirectional=True)
    output, (hn, cn) = lstm(x)
    print(output.shape)  # [batch_size, time_step, 2*hidden_size]
    # 注意，output中第3个维度（也就是2*hidden_size这个部分），
    # 前面hidden_size个值是正向的，后面hidden_size个值是逆向的
    # 所以最后一个time_step的结果中，只有前面hidden_size个值在hn中出现
    print(output)
    print(hn.shape)  # [bidirectional*2, batch_size, hidden_size]
    print(hn)
    # output.shape : [3,5,8] [batch_size, time_step, 2*hidden_size]
    # tensor([[[ 0.0322, -0.1162, -0.0091, -0.0761, 【-0.1878, -0.0995,  0.4181, -0.1844】],
    #          [ 0.0509, -0.1594, -0.0122, -0.1520, -0.1246, -0.0768,  0.3270, -0.0915],
    #          [ 0.0054, -0.1520, -0.0167, -0.2036, -0.1360, -0.0494,  0.3670, -0.1104],
    #          [-0.0456, -0.1496, -0.0269, -0.2669, -0.0534, -0.0301,  0.2054, -0.1105],
    #          [ 【0.0211, -0.1875, -0.0312, -0.2397】, -0.0353, -0.0387,  0.1633, -0.1326]],
    #         [[ 0.0146, -0.0871, -0.0309, -0.0582, 【-0.1409, -0.0749,  0.3836, -0.1914】],
    #          [ 0.0758, -0.1653, -0.0226, -0.0877, -0.1227, -0.0634,  0.3613, -0.1722],
    #          [ 0.0303, -0.1796, -0.0115, -0.1497, -0.1325, -0.0400,  0.3884, -0.0943],
    #          [ 0.0285, -0.1778, -0.0197, -0.2088, -0.0490, -0.0154,  0.2385, -0.1254],
    #          [【-0.0113, -0.1713, -0.0314, -0.2340】, -0.0055,  0.0139,  0.1347, -0.0336]],
    #         [[ 0.0079, -0.0857, -0.0409, -0.0707, 【-0.1214, -0.0129,  0.3164, -0.1672】],
    #          [-0.0310, -0.1083, -0.0197, -0.1680, -0.1434, -0.0385,  0.3470, -0.1024],
    #          [-0.0450, -0.1642, -0.0126, -0.1741, -0.1311, -0.0283,  0.3846, -0.0518],
    #          [-0.0216, -0.1559, -0.0350, -0.2259, -0.0617, -0.0530,  0.2547, -0.1587],
    #          [ 【0.0190, -0.1552, -0.0424, -0.2485】, -0.0242, -0.0523,  0.1439, -0.1433]]], grad_fn=<TransposeBackward0>)

    # hn.shape [bidirectional*2, batch_size, hidden_size]
    # tensor([[[ 0.0211, -0.1875, -0.0312, -0.2397],
    #          [-0.0113, -0.1713, -0.0314, -0.2340],
    #          [ 0.0190, -0.1552, -0.0424, -0.2485]], # 正向的hn最后一个时刻，上面左侧【】中
    #
    #         [[-0.1878, -0.0995,  0.4181, -0.1844],
    #          [-0.1409, -0.0749,  0.3836, -0.1914],  # 反向的hn最后一个时刻，上面右侧【】中
    #          [-0.1214, -0.0129,  0.3164, -0.1672]]], grad_fn=<StackBackward0>)

if __name__ == '__main__':
    test_LSTM()
